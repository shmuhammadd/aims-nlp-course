{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-gram Language Models\n",
    "\n",
    "**Course:** Natural Language Processing  \n",
    "**Topic:** Statistical Language Models - N-grams  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Dict, Tuple\n",
    "import random\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training corpus from the slides\n",
    "corpus = [\n",
    "    \"<s> I am Sam </s>\",\n",
    "    \"<s> Sam I am </s>\",\n",
    "    \"<s> I do not like green eggs and ham </s>\"\n",
    "]\n",
    "\n",
    "print(\"Training Corpus:\")\n",
    "for i, sentence in enumerate(corpus, 1):\n",
    "    print(f\"{i}. {sentence}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Tokenization and Counting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_corpus(corpus: List[str]) -> List[List[str]]:\n",
    "    \"\"\"Tokenize corpus by splitting on whitespace.\"\"\"\n",
    "    return [sentence.split() for sentence in corpus]\n",
    "\n",
    "def build_vocabulary(tokenized_corpus: List[List[str]]) -> set:\n",
    "    \"\"\"Build vocabulary from tokenized corpus.\"\"\"\n",
    "    vocab = set()\n",
    "    for tokens in tokenized_corpus:\n",
    "        vocab.update(tokens)\n",
    "    return vocab\n",
    "\n",
    "def count_unigrams(tokenized_corpus: List[List[str]]) -> Counter:\n",
    "    \"\"\"Count unigram frequencies.\"\"\"\n",
    "    unigram_counts = Counter()\n",
    "    for tokens in tokenized_corpus:\n",
    "        for token in tokens:\n",
    "            unigram_counts[token] += 1\n",
    "    return unigram_counts\n",
    "\n",
    "def count_bigrams(tokenized_corpus: List[List[str]]) -> Counter:\n",
    "    \"\"\"Count bigram frequencies.\"\"\"\n",
    "    bigram_counts = Counter()\n",
    "    for tokens in tokenized_corpus:\n",
    "        for i in range(len(tokens) - 1):\n",
    "            bigram = (tokens[i], tokens[i + 1])\n",
    "            bigram_counts[bigram] += 1\n",
    "    return bigram_counts\n",
    "\n",
    "def count_trigrams(tokenized_corpus: List[List[str]]) -> Counter:\n",
    "    \"\"\"Count trigram frequencies.\"\"\"\n",
    "    trigram_counts = Counter()\n",
    "    for tokens in tokenized_corpus:\n",
    "        for i in range(len(tokens) - 2):\n",
    "            trigram = (tokens[i], tokens[i + 1], tokens[i + 2])\n",
    "            trigram_counts[trigram] += 1\n",
    "    return trigram_counts\n",
    "\n",
    "# Tokenize and count\n",
    "tokenized_corpus = tokenize_corpus(corpus)\n",
    "vocab = build_vocabulary(tokenized_corpus)\n",
    "unigram_counts = count_unigrams(tokenized_corpus)\n",
    "bigram_counts = count_bigrams(tokenized_corpus)\n",
    "trigram_counts = count_trigrams(tokenized_corpus)\n",
    "\n",
    "print(f\"\\nVocabulary size: {len(vocab)}\")\n",
    "print(f\"Total unigrams: {sum(unigram_counts.values())}\")\n",
    "print(f\"Total bigrams: {sum(bigram_counts.values())}\")\n",
    "print(f\"Total trigrams: {sum(trigram_counts.values())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Display Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Unigram Counts:\")\n",
    "for word, count in sorted(unigram_counts.items()):\n",
    "    print(f\"  {word}: {count}\")\n",
    "\n",
    "print(\"\\nBigram Counts:\")\n",
    "for bigram, count in sorted(bigram_counts.items()):\n",
    "    print(f\"  {bigram}: {count}\")\n",
    "\n",
    "print(\"\\nTrigram Counts:\")\n",
    "for trigram, count in sorted(trigram_counts.items()):\n",
    "    print(f\"  {trigram}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Unigram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnigramModel:\n",
    "    \"\"\"Unigram language model.\"\"\"\n",
    "    \n",
    "    def __init__(self, tokenized_corpus: List[List[str]]):\n",
    "        self.unigram_counts = count_unigrams(tokenized_corpus)\n",
    "        self.total_words = sum(self.unigram_counts.values())\n",
    "    \n",
    "    def probability(self, word: str) -> float:\n",
    "        \"\"\"Calculate P(word).\"\"\"\n",
    "        return self.unigram_counts.get(word, 0) / self.total_words\n",
    "    \n",
    "    def log_probability(self, word: str) -> float:\n",
    "        \"\"\"Calculate log P(word).\"\"\"\n",
    "        prob = self.probability(word)\n",
    "        return np.log(prob) if prob > 0 else float('-inf')\n",
    "    \n",
    "    def sentence_probability(self, sentence: List[str]) -> float:\n",
    "        \"\"\"Calculate P(sentence) = product of P(wi).\"\"\"\n",
    "        prob = 1.0\n",
    "        for word in sentence:\n",
    "            prob *= self.probability(word)\n",
    "        return prob\n",
    "    \n",
    "    def sentence_log_probability(self, sentence: List[str]) -> float:\n",
    "        \"\"\"Calculate log P(sentence) = sum of log P(wi).\"\"\"\n",
    "        log_prob = 0.0\n",
    "        for word in sentence:\n",
    "            log_prob += self.log_probability(word)\n",
    "        return log_prob\n",
    "\n",
    "# Create and test unigram model\n",
    "unigram_model = UnigramModel(tokenized_corpus)\n",
    "\n",
    "print(\"Unigram Model - Probabilities:\")\n",
    "test_words = [\"I\", \"am\", \"Sam\", \"<s>\", \"</s>\", \"not\", \"green\"]\n",
    "for word in test_words:\n",
    "    prob = unigram_model.probability(word)\n",
    "    print(f\"  P({word}) = {prob:.4f}\")\n",
    "\n",
    "# Test on a sentence\n",
    "test_sentence = [\"<s>\", \"I\", \"am\", \"Sam\", \"</s>\"]\n",
    "sent_prob = unigram_model.sentence_probability(test_sentence)\n",
    "sent_log_prob = unigram_model.sentence_log_probability(test_sentence)\n",
    "print(f\"\\nP('{' '.join(test_sentence)}') = {sent_prob:.10f}\")\n",
    "print(f\"log P('{' '.join(test_sentence)}') = {sent_log_prob:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Bigram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigramModel:\n",
    "    \"\"\"Bigram language model.\"\"\"\n",
    "    \n",
    "    def __init__(self, tokenized_corpus: List[List[str]]):\n",
    "        self.unigram_counts = count_unigrams(tokenized_corpus)\n",
    "        self.bigram_counts = count_bigrams(tokenized_corpus)\n",
    "    \n",
    "    def probability(self, word: str, previous_word: str) -> float:\n",
    "        \"\"\"Calculate P(word | previous_word).\"\"\"\n",
    "        bigram = (previous_word, word)\n",
    "        bigram_count = self.bigram_counts.get(bigram, 0)\n",
    "        unigram_count = self.unigram_counts.get(previous_word, 0)\n",
    "        \n",
    "        if unigram_count == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        return bigram_count / unigram_count\n",
    "    \n",
    "    def log_probability(self, word: str, previous_word: str) -> float:\n",
    "        \"\"\"Calculate log P(word | previous_word).\"\"\"\n",
    "        prob = self.probability(word, previous_word)\n",
    "        return np.log(prob) if prob > 0 else float('-inf')\n",
    "    \n",
    "    def sentence_probability(self, sentence: List[str]) -> float:\n",
    "        \"\"\"Calculate P(sentence) using bigram model.\"\"\"\n",
    "        if len(sentence) < 2:\n",
    "            return 0.0\n",
    "        \n",
    "        prob = 1.0\n",
    "        for i in range(1, len(sentence)):\n",
    "            prob *= self.probability(sentence[i], sentence[i-1])\n",
    "        return prob\n",
    "    \n",
    "    def sentence_log_probability(self, sentence: List[str]) -> float:\n",
    "        \"\"\"Calculate log P(sentence) using bigram model.\"\"\"\n",
    "        if len(sentence) < 2:\n",
    "            return float('-inf')\n",
    "        \n",
    "        log_prob = 0.0\n",
    "        for i in range(1, len(sentence)):\n",
    "            log_prob += self.log_probability(sentence[i], sentence[i-1])\n",
    "        return log_prob\n",
    "\n",
    "# Create and test bigram model\n",
    "bigram_model = BigramModel(tokenized_corpus)\n",
    "\n",
    "print(\"Bigram Model - Probabilities (from slides):\")\n",
    "test_bigrams = [\n",
    "    (\"<s>\", \"I\"),\n",
    "    (\"<s>\", \"Sam\"),\n",
    "    (\"I\", \"am\"),\n",
    "    (\"I\", \"do\"),\n",
    "    (\"am\", \"Sam\"),\n",
    "    (\"am\", \"</s>\"),\n",
    "    (\"Sam\", \"I\"),\n",
    "    (\"Sam\", \"</s>\")\n",
    "]\n",
    "\n",
    "for w1, w2 in test_bigrams:\n",
    "    prob = bigram_model.probability(w2, w1)\n",
    "    print(f\"  P({w2} | {w1}) = {prob:.4f}\")\n",
    "\n",
    "# Verify against slide examples\n",
    "print(\"\\nVerification against slides:\")\n",
    "print(f\"  P(I | <s>) = {bigram_model.probability('I', '<s>'):.4f} (expected: 0.6667)\")\n",
    "print(f\"  P(Sam | <s>) = {bigram_model.probability('Sam', '<s>'):.4f} (expected: 0.3333)\")\n",
    "print(f\"  P(am | I) = {bigram_model.probability('am', 'I'):.4f} (expected: 0.6667)\")\n",
    "print(f\"  P(</s> | Sam) = {bigram_model.probability('</s>', 'Sam'):.4f} (expected: 0.5000)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. All Bigram Probabilities (as shown in slides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"All Bigram Probabilities:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Get all unique bigrams\n",
    "all_bigrams = sorted(bigram_counts.keys())\n",
    "\n",
    "for bigram in all_bigrams:\n",
    "    w1, w2 = bigram\n",
    "    prob = bigram_model.probability(w2, w1)\n",
    "    count = bigram_counts[bigram]\n",
    "    context_count = unigram_counts[w1]\n",
    "    print(f\"P({w2} | {w1}) = {count}/{context_count} = {prob:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Trigram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrigramModel:\n",
    "    \"\"\"Trigram language model.\"\"\"\n",
    "    \n",
    "    def __init__(self, tokenized_corpus: List[List[str]]):\n",
    "        self.bigram_counts = count_bigrams(tokenized_corpus)\n",
    "        self.trigram_counts = count_trigrams(tokenized_corpus)\n",
    "    \n",
    "    def probability(self, word: str, prev_word1: str, prev_word2: str) -> float:\n",
    "        \"\"\"Calculate P(word | prev_word2, prev_word1).\n",
    "        Note: prev_word2 comes before prev_word1.\n",
    "        \"\"\"\n",
    "        trigram = (prev_word2, prev_word1, word)\n",
    "        bigram = (prev_word2, prev_word1)\n",
    "        \n",
    "        trigram_count = self.trigram_counts.get(trigram, 0)\n",
    "        bigram_count = self.bigram_counts.get(bigram, 0)\n",
    "        \n",
    "        if bigram_count == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        return trigram_count / bigram_count\n",
    "    \n",
    "    def log_probability(self, word: str, prev_word1: str, prev_word2: str) -> float:\n",
    "        \"\"\"Calculate log P(word | prev_word2, prev_word1).\"\"\"\n",
    "        prob = self.probability(word, prev_word1, prev_word2)\n",
    "        return np.log(prob) if prob > 0 else float('-inf')\n",
    "    \n",
    "    def sentence_probability(self, sentence: List[str]) -> float:\n",
    "        \"\"\"Calculate P(sentence) using trigram model.\"\"\"\n",
    "        if len(sentence) < 3:\n",
    "            return 0.0\n",
    "        \n",
    "        prob = 1.0\n",
    "        for i in range(2, len(sentence)):\n",
    "            prob *= self.probability(sentence[i], sentence[i-1], sentence[i-2])\n",
    "        return prob\n",
    "    \n",
    "    def sentence_log_probability(self, sentence: List[str]) -> float:\n",
    "        \"\"\"Calculate log P(sentence) using trigram model.\"\"\"\n",
    "        if len(sentence) < 3:\n",
    "            return float('-inf')\n",
    "        \n",
    "        log_prob = 0.0\n",
    "        for i in range(2, len(sentence)):\n",
    "            log_prob += self.log_probability(sentence[i], sentence[i-1], sentence[i-2])\n",
    "        return log_prob\n",
    "\n",
    "# Create and test trigram model\n",
    "trigram_model = TrigramModel(tokenized_corpus)\n",
    "\n",
    "print(\"Trigram Model - Sample Probabilities:\")\n",
    "test_trigrams = [\n",
    "    (\"<s>\", \"I\", \"am\"),\n",
    "    (\"I\", \"am\", \"Sam\"),\n",
    "    (\"am\", \"Sam\", \"</s>\"),\n",
    "    (\"<s>\", \"I\", \"do\"),\n",
    "    (\"I\", \"do\", \"not\"),\n",
    "]\n",
    "\n",
    "for w1, w2, w3 in test_trigrams:\n",
    "    prob = trigram_model.probability(w3, w2, w1)\n",
    "    print(f\"  P({w3} | {w1}, {w2}) = {prob:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigramGenerator:\n",
    "    \"\"\"Generate text using bigram model.\"\"\"\n",
    "    \n",
    "    def __init__(self, tokenized_corpus: List[List[str]]):\n",
    "        self.unigram_counts = count_unigrams(tokenized_corpus)\n",
    "        self.bigram_counts = count_bigrams(tokenized_corpus)\n",
    "        self.next_word_probs = self._build_next_word_distribution()\n",
    "    \n",
    "    def _build_next_word_distribution(self) -> Dict:\n",
    "        \"\"\"Build distribution over next words for each word.\"\"\"\n",
    "        next_word_dist = defaultdict(lambda: defaultdict(float))\n",
    "        \n",
    "        for (w1, w2), count in self.bigram_counts.items():\n",
    "            next_word_dist[w1][w2] = count / self.unigram_counts[w1]\n",
    "        \n",
    "        return next_word_dist\n",
    "    \n",
    "    def generate(self, max_length: int = 20, start_token: str = \"<s>\") -> List[str]:\n",
    "        \"\"\"Generate a sentence.\"\"\"\n",
    "        sentence = [start_token]\n",
    "        \n",
    "        for _ in range(max_length):\n",
    "            current_word = sentence[-1]\n",
    "            \n",
    "            if current_word not in self.next_word_probs:\n",
    "                break\n",
    "            \n",
    "            next_words = list(self.next_word_probs[current_word].keys())\n",
    "            next_probs = list(self.next_word_probs[current_word].values())\n",
    "            \n",
    "            next_word = np.random.choice(next_words, p=next_probs)\n",
    "            sentence.append(next_word)\n",
    "            \n",
    "            if next_word == \"</s>\":\n",
    "                break\n",
    "        \n",
    "        return sentence\n",
    "\n",
    "# Generate sentences\n",
    "generator = BigramGenerator(tokenized_corpus)\n",
    "\n",
    "print(\"Generated Sentences (Bigram Model):\")\n",
    "print(\"=\" * 60)\n",
    "for i in range(10):\n",
    "    sentence = generator.generate()\n",
    "    print(f\"{i+1}. {' '.join(sentence)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Perplexity Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_perplexity(model, test_sentences: List[List[str]], model_type: str = \"bigram\") -> float:\n",
    "    \"\"\"\n",
    "    Calculate perplexity for a language model.\n",
    "    \n",
    "    Perplexity = exp(-1/N * sum(log P(wi | context)))\n",
    "    \"\"\"\n",
    "    total_log_prob = 0.0\n",
    "    total_words = 0\n",
    "    \n",
    "    for sentence in test_sentences:\n",
    "        if model_type == \"unigram\":\n",
    "            log_prob = model.sentence_log_probability(sentence)\n",
    "            n_words = len(sentence)\n",
    "        elif model_type == \"bigram\":\n",
    "            log_prob = model.sentence_log_probability(sentence)\n",
    "            n_words = len(sentence) - 1  # Exclude <s>\n",
    "        elif model_type == \"trigram\":\n",
    "            log_prob = model.sentence_log_probability(sentence)\n",
    "            n_words = len(sentence) - 2  # Exclude <s> and first word\n",
    "        \n",
    "        if log_prob == float('-inf'):\n",
    "            return float('inf')\n",
    "        \n",
    "        total_log_prob += log_prob\n",
    "        total_words += n_words\n",
    "    \n",
    "    avg_log_prob = total_log_prob / total_words\n",
    "    perplexity = np.exp(-avg_log_prob)\n",
    "    \n",
    "    return perplexity\n",
    "\n",
    "# Calculate perplexity on training data\n",
    "print(\"Perplexity on Training Data:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "unigram_perplexity = calculate_perplexity(unigram_model, tokenized_corpus, \"unigram\")\n",
    "bigram_perplexity = calculate_perplexity(bigram_model, tokenized_corpus, \"bigram\")\n",
    "trigram_perplexity = calculate_perplexity(trigram_model, tokenized_corpus, \"trigram\")\n",
    "\n",
    "print(f\"Unigram Perplexity:  {unigram_perplexity:.4f}\")\n",
    "print(f\"Bigram Perplexity:   {bigram_perplexity:.4f}\")\n",
    "print(f\"Trigram Perplexity:  {trigram_perplexity:.4f}\")\n",
    "print(\"\\nNote: Lower perplexity = better model\")\n",
    "print(\"Note: These are on training data (not ideal for evaluation)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Smoothed Bigram Model (Add-One Smoothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigramModelSmoothed:\n",
    "    \"\"\"Bigram model with add-one (Laplace) smoothing.\"\"\"\n",
    "    \n",
    "    def __init__(self, tokenized_corpus: List[List[str]]):\n",
    "        self.unigram_counts = count_unigrams(tokenized_corpus)\n",
    "        self.bigram_counts = count_bigrams(tokenized_corpus)\n",
    "        self.vocab = build_vocabulary(tokenized_corpus)\n",
    "        self.vocab_size = len(self.vocab)\n",
    "    \n",
    "    def probability(self, word: str, previous_word: str) -> float:\n",
    "        \"\"\"Calculate P(word | previous_word) with add-one smoothing.\n",
    "        \n",
    "        P(wi | wi-1) = (C(wi-1, wi) + 1) / (C(wi-1) + V)\n",
    "        where V is vocabulary size\n",
    "        \"\"\"\n",
    "        bigram = (previous_word, word)\n",
    "        bigram_count = self.bigram_counts.get(bigram, 0)\n",
    "        unigram_count = self.unigram_counts.get(previous_word, 0)\n",
    "        \n",
    "        return (bigram_count + 1) / (unigram_count + self.vocab_size)\n",
    "    \n",
    "    def log_probability(self, word: str, previous_word: str) -> float:\n",
    "        \"\"\"Calculate log P(word | previous_word).\"\"\"\n",
    "        prob = self.probability(word, previous_word)\n",
    "        return np.log(prob)\n",
    "    \n",
    "    def sentence_probability(self, sentence: List[str]) -> float:\n",
    "        \"\"\"Calculate P(sentence) using smoothed bigram model.\"\"\"\n",
    "        if len(sentence) < 2:\n",
    "            return 0.0\n",
    "        \n",
    "        prob = 1.0\n",
    "        for i in range(1, len(sentence)):\n",
    "            prob *= self.probability(sentence[i], sentence[i-1])\n",
    "        return prob\n",
    "    \n",
    "    def sentence_log_probability(self, sentence: List[str]) -> float:\n",
    "        \"\"\"Calculate log P(sentence) using smoothed bigram model.\"\"\"\n",
    "        if len(sentence) < 2:\n",
    "            return float('-inf')\n",
    "        \n",
    "        log_prob = 0.0\n",
    "        for i in range(1, len(sentence)):\n",
    "            log_prob += self.log_probability(sentence[i], sentence[i-1])\n",
    "        return log_prob\n",
    "\n",
    "# Create smoothed model\n",
    "smoothed_bigram_model = BigramModelSmoothed(tokenized_corpus)\n",
    "\n",
    "# Compare with unsmoothed on unseen bigrams\n",
    "print(\"Comparison: Unsmoothed vs Smoothed Bigram Model\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "test_cases = [\n",
    "    (\"I\", \"love\"),  # Unseen bigram\n",
    "    (\"Sam\", \"likes\"),  # Unseen bigram\n",
    "    (\"I\", \"am\"),  # Seen bigram\n",
    "]\n",
    "\n",
    "for w1, w2 in test_cases:\n",
    "    unsmoothed = bigram_model.probability(w2, w1)\n",
    "    smoothed = smoothed_bigram_model.probability(w2, w1)\n",
    "    print(f\"P({w2} | {w1}):\")\n",
    "    print(f\"  Unsmoothed: {unsmoothed:.6f}\")\n",
    "    print(f\"  Smoothed:   {smoothed:.6f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Working with a Larger Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Larger corpus for more interesting results\n",
    "larger_corpus = [\n",
    "    \"<s> I love natural language processing </s>\",\n",
    "    \"<s> Natural language processing is fascinating </s>\",\n",
    "    \"<s> I study natural language processing at university </s>\",\n",
    "    \"<s> Language models are powerful tools </s>\",\n",
    "    \"<s> I love working with language models </s>\",\n",
    "    \"<s> Processing natural language is challenging </s>\",\n",
    "    \"<s> Machine learning helps with natural language </s>\",\n",
    "    \"<s> I enjoy learning about language models </s>\",\n",
    "    \"<s> Deep learning revolutionized natural language processing </s>\",\n",
    "    \"<s> Transformers are state of the art language models </s>\",\n",
    "]\n",
    "\n",
    "# Tokenize\n",
    "larger_tokenized = tokenize_corpus(larger_corpus)\n",
    "\n",
    "# Build models\n",
    "large_unigram = UnigramModel(larger_tokenized)\n",
    "large_bigram = BigramModel(larger_tokenized)\n",
    "large_trigram = TrigramModel(larger_tokenized)\n",
    "\n",
    "print(\"Larger Corpus Statistics:\")\n",
    "print(\"=\" * 60)\n",
    "large_vocab = build_vocabulary(larger_tokenized)\n",
    "large_unigram_counts = count_unigrams(larger_tokenized)\n",
    "large_bigram_counts = count_bigrams(larger_tokenized)\n",
    "\n",
    "print(f\"Vocabulary size: {len(large_vocab)}\")\n",
    "print(f\"Total tokens: {sum(large_unigram_counts.values())}\")\n",
    "print(f\"Unique bigrams: {len(large_bigram_counts)}\")\n",
    "\n",
    "# Calculate perplexities\n",
    "print(\"\\nPerplexities on Larger Corpus:\")\n",
    "large_uni_perp = calculate_perplexity(large_unigram, larger_tokenized, \"unigram\")\n",
    "large_bi_perp = calculate_perplexity(large_bigram, larger_tokenized, \"bigram\")\n",
    "large_tri_perp = calculate_perplexity(large_trigram, larger_tokenized, \"trigram\")\n",
    "\n",
    "print(f\"Unigram Perplexity:  {large_uni_perp:.4f}\")\n",
    "print(f\"Bigram Perplexity:   {large_bi_perp:.4f}\")\n",
    "print(f\"Trigram Perplexity:  {large_tri_perp:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Generate Text from Larger Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate from larger corpus\n",
    "large_generator = BigramGenerator(larger_tokenized)\n",
    "\n",
    "print(\"Generated Sentences from Larger Corpus:\")\n",
    "print(\"=\" * 60)\n",
    "for i in range(15):\n",
    "    sentence = large_generator.generate(max_length=15)\n",
    "    print(f\"{i+1}. {' '.join(sentence)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Visualization: Probability Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize next word probabilities for a given context\n",
    "def plot_next_word_distribution(model: BigramModel, context_word: str, top_k: int = 10):\n",
    "    \"\"\"Plot distribution of next words given context.\"\"\"\n",
    "    # Get all possible next words\n",
    "    next_words = {}\n",
    "    for (w1, w2), count in model.bigram_counts.items():\n",
    "        if w1 == context_word:\n",
    "            next_words[w2] = model.probability(w2, w1)\n",
    "    \n",
    "    if not next_words:\n",
    "        print(f\"No data for context word: {context_word}\")\n",
    "        return\n",
    "    \n",
    "    # Sort by probability\n",
    "    sorted_words = sorted(next_words.items(), key=lambda x: x[1], reverse=True)[:top_k]\n",
    "    words, probs = zip(*sorted_words)\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(range(len(words)), probs)\n",
    "    plt.xticks(range(len(words)), words, rotation=45, ha='right')\n",
    "    plt.xlabel('Next Word')\n",
    "    plt.ylabel('Probability')\n",
    "    plt.title(f'P(word | \"{context_word}\")')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot for different context words\n",
    "context_words = [\"I\", \"language\", \"natural\"]\n",
    "for word in context_words:\n",
    "    if word in large_unigram.unigram_counts:\n",
    "        plot_next_word_distribution(large_bigram, word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Model Comparison Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create comparison table\n",
    "comparison_data = {\n",
    "    'Model': ['Unigram', 'Bigram', 'Trigram'],\n",
    "    'Context Size': [0, 1, 2],\n",
    "    'Markov Order': [0, 1, 2],\n",
    "    'Small Corpus Perplexity': [\n",
    "        f\"{unigram_perplexity:.2f}\",\n",
    "        f\"{bigram_perplexity:.2f}\",\n",
    "        f\"{trigram_perplexity:.2f}\"\n",
    "    ],\n",
    "    'Large Corpus Perplexity': [\n",
    "        f\"{large_uni_perp:.2f}\",\n",
    "        f\"{large_bi_perp:.2f}\",\n",
    "        f\"{large_tri_perp:.2f}\"\n",
    "    ],\n",
    "    'Advantages': [\n",
    "        'Simple, fast',\n",
    "        'Captures local context',\n",
    "        'Better context modeling'\n",
    "    ],\n",
    "    'Disadvantages': [\n",
    "        'No context',\n",
    "        'Limited context',\n",
    "        'Data sparsity'\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(comparison_data)\n",
    "print(\"\\nN-gram Model Comparison:\")\n",
    "print(\"=\" * 100)\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Practical Example: Sentence Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_sentences(model, sentences: List[str], model_type: str = \"bigram\") -> List[Tuple[str, float]]:\n",
    "    \"\"\"Score multiple sentences and return sorted by probability.\"\"\"\n",
    "    scores = []\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        tokens = sentence.split()\n",
    "        \n",
    "        if model_type == \"bigram\":\n",
    "            log_prob = model.sentence_log_probability(tokens)\n",
    "            prob = np.exp(log_prob) if log_prob != float('-inf') else 0.0\n",
    "        elif model_type == \"unigram\":\n",
    "            log_prob = model.sentence_log_probability(tokens)\n",
    "            prob = np.exp(log_prob) if log_prob != float('-inf') else 0.0\n",
    "        \n",
    "        scores.append((sentence, prob, log_prob))\n",
    "    \n",
    "    return sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Test sentences\n",
    "test_sentences = [\n",
    "    \"<s> I love natural language processing </s>\",\n",
    "    \"<s> natural love I processing language </s>\",  # Bad word order\n",
    "    \"<s> I love language models </s>\",\n",
    "    \"<s> models language love I </s>\",  # Bad word order\n",
    "    \"<s> natural language processing is fascinating </s>\",\n",
    "]\n",
    "\n",
    "print(\"Sentence Scoring (Bigram Model on Large Corpus):\")\n",
    "print(\"=\" * 80)\n",
    "scores = score_sentences(large_bigram, test_sentences, \"bigram\")\n",
    "\n",
    "for i, (sent, prob, log_prob) in enumerate(scores, 1):\n",
    "    print(f\"{i}. {sent}\")\n",
    "    print(f\"   Probability: {prob:.10f}\")\n",
    "    print(f\"   Log Probability: {log_prob:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Key Formulas Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Key Formulas for N-gram Language Models\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "print(\"1. Unigram Model:\")\n",
    "print(\"   P(wi) = C(wi) / N\")\n",
    "print()\n",
    "print(\"2. Bigram Model:\")\n",
    "print(\"   P(wi | wi-1) = C(wi-1, wi) / C(wi-1)\")\n",
    "print()\n",
    "print(\"3. Trigram Model:\")\n",
    "print(\"   P(wi | wi-2, wi-1) = C(wi-2, wi-1, wi) / C(wi-2, wi-1)\")\n",
    "print()\n",
    "print(\"4. Sentence Probability (Bigram):\")\n",
    "print(\"   P(w1...wn) = P(w1) * P(w2|w1) * P(w3|w2) * ... * P(wn|wn-1)\")\n",
    "print()\n",
    "print(\"5. Log Space:\")\n",
    "print(\"   log P(w1...wn) = log P(w1) + log P(w2|w1) + ... + log P(wn|wn-1)\")\n",
    "print()\n",
    "print(\"6. Perplexity:\")\n",
    "print(\"   PP(W) = P(w1...wN)^(-1/N)\")\n",
    "print(\"   PP(W) = exp(-1/N * sum(log P(wi | context)))\")\n",
    "print()\n",
    "print(\"7. Add-One Smoothing:\")\n",
    "print(\"   P(wi | wi-1) = (C(wi-1, wi) + 1) / (C(wi-1) + V)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
